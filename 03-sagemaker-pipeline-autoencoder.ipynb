{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "575c15ae-ffe0-4d93-84d8-bf96278c0372",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 3: Add an ML pipeline with PyTorch Autoencoder\n",
    "<div class=\"alert alert-warning\"> This notebook demonstrates PyTorch autoencoder pipeline for anomaly detection. Last tested on a SageMaker Studio JupyterLab instance using the <code>SageMaker Distribution Image 3.0.1</code> and with the SageMaker Python SDK version <code>2.245.0</code></div>\n",
    "\n",
    "In this step you automate our end-to-end ML workflow using [Amazon SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/) and [Amazon SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html). You make feature engineering re-usable, repeatable, and scaleable using [Amazon SageMaker Feature Store](https://aws.amazon.com/sagemaker/feature-store/).\n",
    "\n",
    "This pipeline implements a **PyTorch autoencoder for anomaly detection** with the following key differences from supervised learning:\n",
    "- **Unsupervised learning approach** - No target labels needed for training\n",
    "- **Reconstruction error-based evaluation** - Anomalies have higher reconstruction errors\n",
    "- **Threshold-based classification** - Uses percentile-based thresholds for anomaly detection\n",
    "\n",
    "||||\n",
    "|---|---|---|\n",
    "|1. |Experiment with autoencoder in a notebook ||\n",
    "|2. |Scale with SageMaker AI processing jobs and SageMaker SDK ||\n",
    "|3. |Operationalize with ML pipeline, model registry|**<<<< YOU ARE HERE**|\n",
    "|4. |Add a model deployment pipeline ||\n",
    "|5. |Add streaming inference with SQS ||\n",
    "\n",
    "<div class=\"alert alert-info\"> Make sure you using <code>Python 3</code> kernel in JupyterLab for this notebook.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401790be-c212-4cb1-b265-4fb0e739836a",
   "metadata": {},
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi4gUGxlYXNlIGJlIHBhdGllbnQuPC90ZXh0PgogICAgPHRleHQgeD0iMTAwIiB5PSI1NiIgZm9udC1mYW1pbHk9IkFyaWFsLCBzYW5zLXNlcmlmIiBmb250LXNpemU9IjE0IiBmaWxsPSIjMzMzMzMzIj5Zb3UgY2FuIHNhZmVseSBpZ25vcmUgdGhlIHdhcm5pbmcgbWVzc2FnZXMuPC90ZXh0Pgo8L3N2Zz4K\" alt=\"Time alert open medium\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403f653-1b22-4e80-b980-8cb8b994c69d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:33:44.260319Z",
     "iopub.status.busy": "2025-08-06T09:33:44.259985Z",
     "iopub.status.idle": "2025-08-06T09:33:44.314586Z",
     "shell.execute_reply": "2025-08-06T09:33:44.314036Z",
     "shell.execute_reply.started": "2025-08-06T09:33:44.260297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.249.0', '1.40.3', '2.22.1', '2.6.0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard library\n",
    "import os\n",
    "from time import gmtime, strftime\n",
    "from importlib.metadata import version\n",
    "\n",
    "# Third-party libraries\n",
    "import boto3\n",
    "import mlflow\n",
    "import pandas as pd  # Keep if used in pipeline_steps modules\n",
    "\n",
    "# SageMaker imports\n",
    "import sagemaker\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import TrainingStep, CacheConfig\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger, \n",
    "    ParameterFloat, \n",
    "    ParameterString\n",
    ")\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.function_step import step\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig\n",
    "\n",
    "# IPython/Jupyter specific\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "# Import from local modules (if these exist)\n",
    "\n",
    "(sagemaker.__version__, boto3.__version__, mlflow.__version__, torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8070bde9-9964-4a37-ab2d-ecf68711c865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:49:56.111486Z",
     "iopub.status.busy": "2025-08-06T08:49:56.111161Z",
     "iopub.status.idle": "2025-08-06T08:49:56.149611Z",
     "shell.execute_reply": "2025-08-06T08:49:56.149095Z",
     "shell.execute_reply.started": "2025-08-06T08:49:56.111465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to restore variable 'pytorch_estimator', ignoring (use %store -d to forget!)\n",
      "The error was: <class 'KeyError'>\n",
      "Stored variables and their in-db values:\n",
      "baseline_s3_url                        -> 's3://sagemaker-us-west-2-224425919845/from-idea-t\n",
      "bucket_name                            -> 'sagemaker-us-west-2-224425919845'\n",
      "bucket_prefix                          -> 'from-idea-to-prod/autoencoder'\n",
      "dataset_file_local_path                -> 'data/bank-additional/bank-additional-full.csv'\n",
      "domain_id                              -> 'd-rtctvdud9qsp'\n",
      "endpoint_name                          -> 'from-idea-to-prod-autoencoder-endpoint-06-04-51-2\n",
      "evaluation_s3_url                      -> 's3://sagemaker-us-west-2-224425919845/from-idea-t\n",
      "initialized                            -> True\n",
      "input_s3_url                           -> 's3://sagemaker-us-west-2-224425919845/from-idea-t\n",
      "mlflow_arn                             -> 'arn:aws:sagemaker:us-west-2:224425919845:mlflow-t\n",
      "mlflow_name                            -> 'mlflow-d-rtctvdud9qsp'\n",
      "model_package_group_name               -> 'from-idea-to-prod-autoencoder-pipeline-model-05-0\n",
      "output_data_uri                        -> 's3://sagemaker-us-west-2-224425919845/from-idea-t\n",
      "output_s3_url                          -> 's3://sagemaker-us-west-2-224425919845/from-idea-t\n",
      "pipeline_name                          -> 'from-idea-to-prod-autoencoder-pipeline-05-08-09-4\n",
      "prediction_baseline_s3_url             -> 's3://sagemaker-us-west-2-224425919845/from-idea-t\n",
      "preprocessing_job_name                 -> 'banking-autoencoder-preprocessing-2025-07-24-06-0\n",
      "pytorch_estimator                      -> '<unavailable>'\n",
      "region                                 -> 'us-west-2'\n",
      "sm_image                               -> 'arn:aws:sagemaker:us-west-2:542918446943:image/sa\n",
      "sm_image_version                       -> '3.3.1'\n",
      "sm_role                                -> 'arn:aws:iam::224425919845:role/tm-ws-SageMakerExe\n",
      "space_name                             -> 'jupyterlab-space'\n",
      "test_s3_url                            -> 's3://sagemaker-us-west-2-224425919845/from-idea-t\n",
      "train_s3_url                           -> 's3://sagemaker-us-west-2-224425919845/from-idea-t\n",
      "training_job_name                      -> 'banking-autoencoder-pytorch-2025-07-24-07-47-36'\n",
      "user_profile_name                      -> 'studio-user-7788a530'\n",
      "validation_s3_url                      -> 's3://sagemaker-us-west-2-224425919845/from-idea-t\n"
     ]
    }
   ],
   "source": [
    "%store -r \n",
    "\n",
    "%store\n",
    "\n",
    "try:\n",
    "    initialized\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN 00-start-here notebook   \")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35af367a-330b-4a38-b8e9-8eb6c91b2848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:50:22.375394Z",
     "iopub.status.busy": "2025-08-06T08:50:22.375089Z",
     "iopub.status.idle": "2025-08-06T08:50:22.405989Z",
     "shell.execute_reply": "2025-08-06T08:50:22.405468Z",
     "shell.execute_reply.started": "2025-08-06T08:50:22.375371Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set names of pipeline objects, experiment, and a model\n",
    "project = \"from-idea-to-prod\"\n",
    "\n",
    "current_timestamp = strftime('%d-%H-%M-%S', gmtime())\n",
    "\n",
    "registered_model_name = f\"{project}-autoencoder-pipeline-model-{current_timestamp}\"\n",
    "experiment_name = f\"{project}-autoencoder-pipeline-{current_timestamp}\"\n",
    "pipeline_name = f\"{project}-autoencoder-pipeline-{current_timestamp}\"\n",
    "pipeline_model_name = f\"{project}-model-autoencoder\"\n",
    "model_package_group_name = registered_model_name\n",
    "endpoint_config_name = f\"{project}-autoencoder-endpoint-config\"\n",
    "endpoint_name = f\"{project}-autoencoder-endpoint\"\n",
    "model_approval_status = \"PendingManualApproval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "117780bf-bb92-44fc-a9a0-d0f81b7f8e80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:51:24.954377Z",
     "iopub.status.busy": "2025-08-06T08:51:24.954044Z",
     "iopub.status.idle": "2025-08-06T08:51:24.985319Z",
     "shell.execute_reply": "2025-08-06T08:51:24.984797Z",
     "shell.execute_reply.started": "2025-08-06T08:51:24.954354Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set instance types and counts for autoencoder training\n",
    "process_instance_type = \"ml.m5.large\"\n",
    "train_instance_type = \"ml.g4dn.xlarge\"  # Slightly larger for PyTorch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6881902-a75b-4c55-9c72-7443b8c5bfb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:51:38.786420Z",
     "iopub.status.busy": "2025-08-06T08:51:38.786093Z",
     "iopub.status.idle": "2025-08-06T08:51:38.817580Z",
     "shell.execute_reply": "2025-08-06T08:51:38.817008Z",
     "shell.execute_reply.started": "2025-08-06T08:51:38.786397Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set S3 urls for various datasets produced in the pipeline\n",
    "output_s3_prefix = f\"s3://{bucket_name}/{bucket_prefix}\"\n",
    "output_s3_url = f\"{output_s3_prefix}/output\"\n",
    "\n",
    "train_s3_url = f\"{output_s3_prefix}/train\"\n",
    "validation_s3_url = f\"{output_s3_prefix}/validation\"\n",
    "test_s3_url = f\"{output_s3_prefix}/test\"\n",
    "evaluation_s3_url = f\"{output_s3_prefix}/evaluation\"\n",
    "\n",
    "baseline_s3_url = f\"{output_s3_prefix}/baseline\"\n",
    "baseline_results_s3_url = f\"{baseline_s3_url}/results\"\n",
    "\n",
    "prediction_baseline_s3_url = f\"{output_s3_prefix}/prediction_baseline\"\n",
    "prediction_baseline_results_s3_url=f\"{prediction_baseline_s3_url}/results\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aacbdfba-c91c-449c-9186-72ebe2e9a889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:52:52.270402Z",
     "iopub.status.busy": "2025-08-06T08:52:52.270080Z",
     "iopub.status.idle": "2025-08-06T08:52:52.305804Z",
     "shell.execute_reply": "2025-08-06T08:52:52.305219Z",
     "shell.execute_reply.started": "2025-08-06T08:52:52.270380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_s3_url' (str)\n",
      "Stored 'validation_s3_url' (str)\n",
      "Stored 'test_s3_url' (str)\n",
      "Stored 'baseline_s3_url' (str)\n",
      "Stored 'pipeline_name' (str)\n",
      "Stored 'model_package_group_name' (str)\n",
      "Stored 'evaluation_s3_url' (str)\n",
      "Stored 'prediction_baseline_s3_url' (str)\n",
      "Stored 'output_s3_url' (str)\n"
     ]
    }
   ],
   "source": [
    "%store train_s3_url\n",
    "%store validation_s3_url\n",
    "%store test_s3_url\n",
    "%store baseline_s3_url\n",
    "%store pipeline_name\n",
    "%store model_package_group_name\n",
    "%store evaluation_s3_url\n",
    "%store prediction_baseline_s3_url\n",
    "%store output_s3_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5580383-616d-4f6b-8b6a-b17d1564712f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:53:04.109390Z",
     "iopub.status.busy": "2025-08-06T08:53:04.109063Z",
     "iopub.status.idle": "2025-08-06T08:53:04.140458Z",
     "shell.execute_reply": "2025-08-06T08:53:04.139844Z",
     "shell.execute_reply.started": "2025-08-06T08:53:04.109368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train S3 url: s3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/train\n",
      "Validation S3 url: s3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/validation\n",
      "Test S3 url: s3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/test\n",
      "Data baseline S3 url: s3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/baseline\n",
      "Evaluation metrics S3 url: s3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/evaluation\n",
      "Model prediction baseline S3 url: s3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/prediction_baseline\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train S3 url: {train_s3_url}\")\n",
    "print(f\"Validation S3 url: {validation_s3_url}\")\n",
    "print(f\"Test S3 url: {test_s3_url}\")\n",
    "print(f\"Data baseline S3 url: {baseline_s3_url}\")\n",
    "print(f\"Evaluation metrics S3 url: {evaluation_s3_url}\")\n",
    "print(f\"Model prediction baseline S3 url: {prediction_baseline_s3_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0af67942-d89d-4b0f-bc2d-1d37f3937b29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:54:02.695574Z",
     "iopub.status.busy": "2025-08-06T08:54:02.695244Z",
     "iopub.status.idle": "2025-08-06T08:54:02.728060Z",
     "shell.execute_reply": "2025-08-06T08:54:02.727456Z",
     "shell.execute_reply.started": "2025-08-06T08:54:02.695552Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_pytorch_autoencoder_estimator(\n",
    "    session,\n",
    "    instance_type,\n",
    "    output_s3_url,\n",
    "    base_job_name,\n",
    "):\n",
    "    \"\"\"Create PyTorch estimator for autoencoder training\"\"\"\n",
    "    estimator = PyTorch(\n",
    "        entry_point='train_autoencoder.py',\n",
    "        source_dir='./training',\n",
    "        role=sagemaker.get_execution_role(),\n",
    "        instance_type=instance_type,\n",
    "        instance_count=1,\n",
    "        framework_version='1.12',\n",
    "        py_version='py38',\n",
    "        output_path=output_s3_url,\n",
    "        sagemaker_session=session,\n",
    "        base_job_name=base_job_name,\n",
    "        environment={\n",
    "            'MLFLOW_TRACKING_ARN': mlflow_arn,\n",
    "            'MLFLOW_EXPERIMENT_NAME': experiment_name,\n",
    "            'REGION': region\n",
    "        },\n",
    "        enable_sagemaker_metrics=True,\n",
    "        metric_definitions=[\n",
    "            {'Name': 'train_loss', 'Regex': 'Train Loss: ([0-9\\\\.]+)'},\n",
    "            {'Name': 'val_loss', 'Regex': 'Val Loss: ([0-9\\\\.]+)'},\n",
    "            {'Name': 'reconstruction_threshold', 'Regex': 'threshold.*: ([0-9\\\\.]+)'}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Set hyperparameters for autoencoder\n",
    "    estimator.set_hyperparameters(\n",
    "        encoding_dim=32,\n",
    "        dropout_rate=0.2,\n",
    "        learning_rate=0.001,\n",
    "        batch_size=64,\n",
    "        num_epochs=100,\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "\n",
    "    return estimator\n",
    "\n",
    "def get_pytorch_processor(\n",
    "    session,\n",
    "    instance_type,\n",
    "    base_job_name,\n",
    "):\n",
    "    \"\"\"Create PyTorch processor for data processing\"\"\"\n",
    "    processor = FrameworkProcessor(\n",
    "        estimator_cls=PyTorch,\n",
    "        framework_version='1.12',\n",
    "        py_version='py38',\n",
    "        role=sagemaker.get_execution_role(),\n",
    "        instance_type=instance_type,\n",
    "        instance_count=1,\n",
    "        base_job_name=base_job_name,\n",
    "        sagemaker_session=session,\n",
    "        env={\n",
    "            'MLFLOW_TRACKING_ARN': mlflow_arn,\n",
    "            'MLFLOW_EXPERIMENT_NAME': experiment_name,\n",
    "            'REGION': region\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return processor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cea3e8-2fe0-4260-b5b1-a872bbdf23ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:54:13.344504Z",
     "iopub.status.busy": "2025-08-06T08:54:13.344167Z",
     "iopub.status.idle": "2025-08-06T08:54:13.375128Z",
     "shell.execute_reply": "2025-08-06T08:54:13.374456Z",
     "shell.execute_reply.started": "2025-08-06T08:54:13.344480Z"
    }
   },
   "source": [
    "## Configure MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b82e4383-b625-4a74-86f8-ebd570210a8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:54:31.805323Z",
     "iopub.status.busy": "2025-08-06T08:54:31.804844Z",
     "iopub.status.idle": "2025-08-06T08:54:32.051091Z",
     "shell.execute_reply": "2025-08-06T08:54:32.050513Z",
     "shell.execute_reply.started": "2025-08-06T08:54:31.805299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using server mlflow-d-rtctvdud9qsp\n"
     ]
    }
   ],
   "source": [
    "sm = boto3.client(\"sagemaker\")\n",
    "\n",
    "while sm.describe_mlflow_tracking_server(TrackingServerName=mlflow_name)['TrackingServerStatus'] != 'Created':\n",
    "    print(f\"The MLflow server {mlflow_name} is not in the status 'Created'\")\n",
    "    sleep(30)\n",
    "else:\n",
    "    print(f\"Using server {mlflow_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8ff11c1-0531-47c6-b1ea-5adfd768c712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:54:39.077041Z",
     "iopub.status.busy": "2025-08-06T08:54:39.076753Z",
     "iopub.status.idle": "2025-08-06T08:54:39.361805Z",
     "shell.execute_reply": "2025-08-06T08:54:39.361330Z",
     "shell.execute_reply.started": "2025-08-06T08:54:39.077019Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/06 08:54:39 INFO mlflow.tracking.fluent: Experiment with name 'from-idea-to-prod-autoencoder-pipeline-06-08-50-22' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(mlflow_arn)\n",
    "experiment = mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1658a2-1214-4976-bc07-d1b450ba1730",
   "metadata": {},
   "source": [
    "## A SageMaker pipeline\n",
    "\n",
    "### Setup pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee2d2155-2bb3-4f85-9cc1-0f977d31af73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:56:43.083500Z",
     "iopub.status.busy": "2025-08-06T08:56:43.083163Z",
     "iopub.status.idle": "2025-08-06T08:56:43.115750Z",
     "shell.execute_reply": "2025-08-06T08:56:43.115160Z",
     "shell.execute_reply.started": "2025-08-06T08:56:43.083477Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set processing instance type\n",
    "process_instance_type_param = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=process_instance_type,\n",
    ")\n",
    "\n",
    "# Set training instance type\n",
    "train_instance_type_param = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=train_instance_type,\n",
    ")\n",
    "\n",
    "# Set model approval status for the model registry\n",
    "model_approval_status_param = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=model_approval_status\n",
    ")\n",
    "\n",
    "# Minimal threshold for model performance on the test dataset (ROC AUC for autoencoder)\n",
    "test_score_threshold_param = ParameterFloat(\n",
    "    name=\"TestScoreThreshold\",\n",
    "    default_value=0.65  # Lower threshold for autoencoder anomaly detection\n",
    ")\n",
    "\n",
    "# Parametrize the S3 url for input dataset\n",
    "input_s3_url_param = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=input_s3_url,\n",
    ")\n",
    "\n",
    "# Model package group name\n",
    "model_package_group_name_param = ParameterString(\n",
    "    name=\"ModelPackageGroupName\",\n",
    "    default_value=model_package_group_name,\n",
    ")\n",
    "\n",
    "# MLflow tracking server ARN\n",
    "tracking_server_arn_param = ParameterString(\n",
    "    name=\"TrackingServerARN\",\n",
    "    default_value=mlflow_arn,\n",
    ")\n",
    "\n",
    "# Autoencoder hyperparameters\n",
    "encoding_dim_param = ParameterInteger(name=\"EncodingDim\", default_value=32)\n",
    "dropout_rate_param = ParameterFloat(name=\"DropoutRate\", default_value=0.2)\n",
    "learning_rate_param = ParameterFloat(name=\"LearningRate\", default_value=0.001)\n",
    "batch_size_param = ParameterInteger(name=\"BatchSize\", default_value=64)\n",
    "num_epochs_param = ParameterInteger(name=\"NumEpochs\", default_value=100)\n",
    "weight_decay_param = ParameterFloat(name=\"WeightDecay\", default_value=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "401d6d50-b888-4a0c-bb4d-fc6f88f63583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:57:07.358122Z",
     "iopub.status.busy": "2025-08-06T08:57:07.357851Z",
     "iopub.status.idle": "2025-08-06T08:57:08.568758Z",
     "shell.execute_reply": "2025-08-06T08:57:08.568122Z",
     "shell.execute_reply.started": "2025-08-06T08:57:07.358100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 06:22:17    5834924 bank-additional-full.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {input_s3_url}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0362f26e-2ce0-40a8-9173-3e8cf94812ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:58:03.933959Z",
     "iopub.status.busy": "2025-08-06T08:58:03.933607Z",
     "iopub.status.idle": "2025-08-06T08:58:03.969470Z",
     "shell.execute_reply": "2025-08-06T08:58:03.968878Z",
     "shell.execute_reply.started": "2025-08-06T08:58:03.933932Z"
    }
   },
   "source": [
    "### Implement and test the pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d78a1203-9a02-497c-b0e0-9bf09dceddde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:59:41.960532Z",
     "iopub.status.busy": "2025-08-06T08:59:41.960204Z",
     "iopub.status.idle": "2025-08-06T08:59:42.155312Z",
     "shell.execute_reply": "2025-08-06T08:59:42.154630Z",
     "shell.execute_reply.started": "2025-08-06T08:59:41.960512Z"
    }
   },
   "outputs": [],
   "source": [
    "%mkdir -p pipeline_steps/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51a5b15a-869b-499c-adb4-5182ff6f1637",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T08:59:42.750053Z",
     "iopub.status.busy": "2025-08-06T08:59:42.749482Z",
     "iopub.status.idle": "2025-08-06T08:59:42.789212Z",
     "shell.execute_reply": "2025-08-06T08:59:42.788694Z",
     "shell.execute_reply.started": "2025-08-06T08:59:42.750024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline_steps/preprocess_autoencoder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline_steps/preprocess_autoencoder.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import mlflow\n",
    "from time import gmtime, strftime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import boto3\n",
    "\n",
    "def preprocess_autoencoder(\n",
    "    input_data_s3_path,\n",
    "    output_s3_prefix,\n",
    "    tracking_server_arn,\n",
    "    experiment_name,\n",
    "    pipeline_run_name=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess data for autoencoder training - unsupervised learning approach\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up MLflow\n",
    "    mlflow.set_tracking_uri(tracking_server_arn)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    run_name = f\"preprocess-autoencoder-{strftime('%d-%H-%M-%S', gmtime())}\"\n",
    "    if pipeline_run_name:\n",
    "        run_name = f\"preprocess-{pipeline_run_name}\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name, description=\"Data preprocessing for autoencoder\") as run:\n",
    "        \n",
    "        # Download and load data\n",
    "        print(f\"Loading data from {input_data_s3_path}\")\n",
    "        \n",
    "        # Extract bucket and key from S3 path\n",
    "        s3_parts = input_data_s3_path.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "        bucket = s3_parts[0]\n",
    "        key = s3_parts[1]\n",
    "        \n",
    "        # Download file locally\n",
    "        s3_client = boto3.client('s3')\n",
    "        local_file = '/tmp/input_data.csv'\n",
    "        s3_client.download_file(bucket, key, local_file)\n",
    "        \n",
    "        # Load data\n",
    "        df_raw = pd.read_csv(local_file, sep=\";\")\n",
    "        print(f\"Original data shape: {df_raw.shape}\")\n",
    "        \n",
    "        # Feature engineering (same as before but we'll use all features for reconstruction)\n",
    "        df_data = df_raw.copy()\n",
    "        df_data[\"no_previous_contact\"] = np.where(df_data[\"pdays\"] == 999, 1, 0)\n",
    "        df_data[\"not_working\"] = np.where(\n",
    "            np.in1d(df_data[\"job\"], [\"student\", \"retired\", \"unemployed\"]), 1, 0\n",
    "        )\n",
    "\n",
    "        # Remove unnecessary data but keep more features for autoencoder\n",
    "        df_model_data = df_data.drop(\n",
    "            [\"duration\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\", \"nr.employed\"],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        # Age binning\n",
    "        bins = [18, 30, 40, 50, 60, 70, 90]\n",
    "        labels = ['18-29', '30-39', '40-49', '50-59', '60-69', '70-plus']\n",
    "        df_model_data['age_range'] = pd.cut(df_model_data.age, bins, labels=labels, include_lowest=True)\n",
    "        df_model_data = pd.concat([df_model_data, pd.get_dummies(df_model_data['age_range'], prefix='age', dtype=int)], axis=1)\n",
    "        df_model_data.drop('age', axis=1, inplace=True)\n",
    "        df_model_data.drop('age_range', axis=1, inplace=True)\n",
    "\n",
    "        # Scale numerical features\n",
    "        scaled_features = ['pdays', 'previous', 'campaign']\n",
    "        scaler = StandardScaler()\n",
    "        df_model_data[scaled_features] = scaler.fit_transform(df_model_data[scaled_features])\n",
    "\n",
    "        # Convert categorical variables to dummy variables\n",
    "        df_model_data = pd.get_dummies(df_model_data, dtype=int)\n",
    "\n",
    "        # For autoencoder, we'll separate the target for evaluation but not use it in training\n",
    "        target_col = \"y\"\n",
    "        if 'y_yes' in df_model_data.columns and 'y_no' in df_model_data.columns:\n",
    "            # Keep target for anomaly evaluation\n",
    "            target_data = df_model_data[\"y_yes\"].copy()\n",
    "            # Remove target columns from features for unsupervised learning\n",
    "            feature_data = df_model_data.drop([\"y_no\", \"y_yes\"], axis=1)\n",
    "        else:\n",
    "            target_data = None\n",
    "            feature_data = df_model_data\n",
    "        \n",
    "        print(f\"Feature data shape after processing: {feature_data.shape}\")\n",
    "        \n",
    "        # For autoencoder, we typically use normal data for training and test on both normal and anomalous\n",
    "        # Split data: 70% train, 15% validation, 15% test\n",
    "        train_size = int(0.7 * len(feature_data))\n",
    "        val_size = int(0.15 * len(feature_data))\n",
    "        \n",
    "        # Shuffle data\n",
    "        shuffled_indices = np.random.permutation(len(feature_data))\n",
    "        feature_data_shuffled = feature_data.iloc[shuffled_indices].reset_index(drop=True)\n",
    "        if target_data is not None:\n",
    "            target_data_shuffled = target_data.iloc[shuffled_indices].reset_index(drop=True)\n",
    "        \n",
    "        # Split features\n",
    "        train_features = feature_data_shuffled[:train_size]\n",
    "        val_features = feature_data_shuffled[train_size:train_size + val_size]\n",
    "        test_features = feature_data_shuffled[train_size + val_size:]\n",
    "        \n",
    "        # Split targets (for evaluation)\n",
    "        if target_data is not None:\n",
    "            train_targets = target_data_shuffled[:train_size]\n",
    "            val_targets = target_data_shuffled[train_size:train_size + val_size]\n",
    "            test_targets = target_data_shuffled[train_size + val_size:]\n",
    "        \n",
    "        print(f\"Data split > train:{train_features.shape} | validation:{val_features.shape} | test:{test_features.shape}\")\n",
    "        \n",
    "        # Log parameters to MLflow\n",
    "        mlflow.log_params({\n",
    "            \"train_features\": train_features.shape,\n",
    "            \"val_features\": val_features.shape,\n",
    "            \"test_features\": test_features.shape,\n",
    "            \"total_features\": feature_data.shape[1]\n",
    "        })\n",
    "\n",
    "        mlflow.set_tags({\n",
    "            'mlflow.source.type': 'JOB',\n",
    "            'model_type': 'autoencoder',\n",
    "            'step': 'preprocessing'\n",
    "        })\n",
    "        \n",
    "        # Upload datasets to S3\n",
    "        s3_client = boto3.client('s3')\n",
    "        \n",
    "        # Extract bucket from output prefix\n",
    "        output_bucket = output_s3_prefix.replace(\"s3://\", \"\").split(\"/\")[0]\n",
    "        output_prefix = \"/\".join(output_s3_prefix.replace(\"s3://\", \"\").split(\"/\")[1:])\n",
    "        \n",
    "        # Save and upload train data\n",
    "        train_local = '/tmp/train.csv'\n",
    "        train_features.to_csv(train_local, index=False, header=False)\n",
    "        train_key = f\"{output_prefix}/train/train.csv\"\n",
    "        s3_client.upload_file(train_local, output_bucket, train_key)\n",
    "        train_s3_url = f\"s3://{output_bucket}/{train_key}\"\n",
    "        \n",
    "        # Save and upload validation data\n",
    "        val_local = '/tmp/validation.csv'\n",
    "        val_features.to_csv(val_local, index=False, header=False)\n",
    "        val_key = f\"{output_prefix}/validation/validation.csv\"\n",
    "        s3_client.upload_file(val_local, output_bucket, val_key)\n",
    "        validation_s3_url = f\"s3://{output_bucket}/{val_key}\"\n",
    "        \n",
    "        # Save and upload test features\n",
    "        test_x_local = '/tmp/test_features.csv'\n",
    "        test_features.to_csv(test_x_local, index=False, header=False)\n",
    "        test_x_key = f\"{output_prefix}/test/test_features.csv\"\n",
    "        s3_client.upload_file(test_x_local, output_bucket, test_x_key)\n",
    "        test_x_s3_url = f\"s3://{output_bucket}/{test_x_key}\"\n",
    "        \n",
    "        # Save and upload test targets (for evaluation)\n",
    "        if target_data is not None:\n",
    "            test_y_local = '/tmp/test_targets.csv'\n",
    "            test_targets.to_csv(test_y_local, index=False, header=False)\n",
    "            test_y_key = f\"{output_prefix}/test/test_targets.csv\"\n",
    "            s3_client.upload_file(test_y_local, output_bucket, test_y_key)\n",
    "            test_y_s3_url = f\"s3://{output_bucket}/{test_y_key}\"\n",
    "        else:\n",
    "            test_y_s3_url = None\n",
    "        \n",
    "        # Save and upload baseline data\n",
    "        baseline_local = '/tmp/baseline.csv'\n",
    "        feature_data.to_csv(baseline_local, index=False, header=False)\n",
    "        baseline_key = f\"{output_prefix}/baseline/baseline.csv\"\n",
    "        s3_client.upload_file(baseline_local, output_bucket, baseline_key)\n",
    "        baseline_s3_url = f\"s3://{output_bucket}/{baseline_key}\"\n",
    "        \n",
    "        # Log artifacts to MLflow\n",
    "        mlflow.log_artifact(baseline_local, \"baseline\")\n",
    "        \n",
    "        print(\"## Processing complete.\")\n",
    "        \n",
    "        return {\n",
    "            'train_data': train_s3_url,\n",
    "            'validation_data': validation_s3_url,\n",
    "            'test_x_data': test_x_s3_url,\n",
    "            'test_y_data': test_y_s3_url,\n",
    "            'baseline_data': baseline_s3_url,\n",
    "            'experiment_name': experiment_name,\n",
    "            'pipeline_run_id': pipeline_run_name or run.info.run_id\n",
    "        }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--input-data-s3-path', type=str, required=True)\n",
    "    parser.add_argument('--output-s3-prefix', type=str, required=True)\n",
    "    parser.add_argument('--tracking-server-arn', type=str, required=True)\n",
    "    parser.add_argument('--experiment-name', type=str, required=True)\n",
    "    parser.add_argument('--pipeline-run-name', type=str, default=None)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    result = preprocess_autoencoder(\n",
    "        input_data_s3_path=args.input_data_s3_path,\n",
    "        output_s3_prefix=args.output_s3_prefix,\n",
    "        tracking_server_arn=args.tracking_server_arn,\n",
    "        experiment_name=args.experiment_name,\n",
    "        pipeline_run_name=args.pipeline_run_name\n",
    "    )\n",
    "    \n",
    "    print(f\"Preprocessing result: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068fad09-e1f9-484f-859a-bfd22232d92d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:00:00.885825Z",
     "iopub.status.busy": "2025-08-06T09:00:00.885213Z",
     "iopub.status.idle": "2025-08-06T09:00:00.916716Z",
     "shell.execute_reply": "2025-08-06T09:00:00.916150Z",
     "shell.execute_reply.started": "2025-08-06T09:00:00.885797Z"
    }
   },
   "source": [
    "#### Processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f717562e-7bd1-488b-8d0d-58dfcac6d6f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:00:12.768292Z",
     "iopub.status.busy": "2025-08-06T09:00:12.767878Z",
     "iopub.status.idle": "2025-08-06T09:00:12.804585Z",
     "shell.execute_reply": "2025-08-06T09:00:12.803980Z",
     "shell.execute_reply.started": "2025-08-06T09:00:12.768269Z"
    }
   },
   "outputs": [],
   "source": [
    "from pipeline_steps.preprocess_autoencoder import preprocess_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ab6f7c8-4418-4c87-8e87-fa9a470c9ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:00:18.144486Z",
     "iopub.status.busy": "2025-08-06T09:00:18.144175Z",
     "iopub.status.idle": "2025-08-06T09:00:21.162581Z",
     "shell.execute_reply": "2025-08-06T09:00:21.162065Z",
     "shell.execute_reply.started": "2025-08-06T09:00:18.144463Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/06 09:00:18 INFO mlflow.tracking.fluent: Experiment with name 'local-test-06-08-50-22' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from s3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/input/bank-additional-full.csv\n",
      "Original data shape: (41188, 21)\n",
      "Feature data shape after processing: (41188, 64)\n",
      "Data split > train:(28831, 64) | validation:(6178, 64) | test:(6179, 64)\n",
      "## Processing complete.\n",
      "üèÉ View run preprocess-autoencoder-06-09-00-18 at: https://us-west-2.experiments.sagemaker.aws/#/experiments/56/runs/c7e41bb462cf4562aae4faf914d4d6b5\n",
      "üß™ View experiment at: https://us-west-2.experiments.sagemaker.aws/#/experiments/56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_data': 's3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/train/train.csv',\n",
       " 'validation_data': 's3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/validation/validation.csv',\n",
       " 'test_x_data': 's3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/test/test_features.csv',\n",
       " 'test_y_data': 's3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/test/test_targets.csv',\n",
       " 'baseline_data': 's3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/baseline/baseline.csv',\n",
       " 'experiment_name': 'local-test-06-08-50-22',\n",
       " 'pipeline_run_id': 'c7e41bb462cf4562aae4faf914d4d6b5'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_preprocess = preprocess_autoencoder(\n",
    "    input_data_s3_path=input_s3_url,\n",
    "    output_s3_prefix=output_s3_prefix,\n",
    "    tracking_server_arn=mlflow_arn,\n",
    "    experiment_name=f\"local-test-{current_timestamp}\"\n",
    ")\n",
    "r_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21dca32c-5f0f-493a-abe7-a5ad67bea829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:00:57.901552Z",
     "iopub.status.busy": "2025-08-06T09:00:57.901211Z",
     "iopub.status.idle": "2025-08-06T09:00:58.941931Z",
     "shell.execute_reply": "2025-08-06T09:00:58.941214Z",
     "shell.execute_reply.started": "2025-08-06T09:00:57.901527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 09:00:20    1121718 test_features.csv\n",
      "2025-08-06 09:00:21      12358 test_targets.csv\n",
      "2025-07-28 02:51:48     600465 test_x.csv\n",
      "2025-07-28 02:51:47       8238 test_y.csv\n"
     ]
    }
   ],
   "source": [
    "# check that the function generated output\n",
    "!aws s3 ls {output_s3_prefix}/test/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa50d9b-0ee4-4b90-aaab-7fd7f9597d15",
   "metadata": {},
   "source": [
    "#### Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa5a4567-021f-4a98-9e18-6daf043153d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:01:20.440796Z",
     "iopub.status.busy": "2025-08-06T09:01:20.440413Z",
     "iopub.status.idle": "2025-08-06T09:01:22.070274Z",
     "shell.execute_reply": "2025-08-06T09:01:22.069628Z",
     "shell.execute_reply.started": "2025-08-06T09:01:20.440768Z"
    }
   },
   "outputs": [],
   "source": [
    "# use PipelineSession() in the estimator for pipeline construction\n",
    "estimator = get_pytorch_autoencoder_estimator(\n",
    "    session=sagemaker.Session(),\n",
    "    instance_type=train_instance_type,\n",
    "    output_s3_url=output_s3_url,\n",
    "    base_job_name=f\"{project}-autoencoder-train\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a9cca47-0e2b-4383-9ae6-e4f4823d7a5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:01:59.065403Z",
     "iopub.status.busy": "2025-08-06T09:01:59.065089Z",
     "iopub.status.idle": "2025-08-06T09:01:59.100235Z",
     "shell.execute_reply": "2025-08-06T09:01:59.099653Z",
     "shell.execute_reply.started": "2025-08-06T09:01:59.065377Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the training inputs using the outputs from preprocess function\n",
    "training_inputs = {\n",
    "    \"train\": TrainingInput(\n",
    "        s3_data=r_preprocess['train_data'],\n",
    "        content_type=\"text/csv\",\n",
    "    ),\n",
    "    \"validation\": TrainingInput(\n",
    "        s3_data=r_preprocess['validation_data'],\n",
    "        content_type=\"text/csv\",\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b79e4a-4df2-4aad-a0a4-da573ab5dc99",
   "metadata": {},
   "source": [
    "## Prepare evaluate step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72798f64-5ce9-49cc-887f-ceaf70f3b147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:03:40.804811Z",
     "iopub.status.busy": "2025-08-06T09:03:40.804461Z",
     "iopub.status.idle": "2025-08-06T09:03:40.844331Z",
     "shell.execute_reply": "2025-08-06T09:03:40.843803Z",
     "shell.execute_reply.started": "2025-08-06T09:03:40.804785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline_steps/evaluate_autoencoder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline_steps/evaluate_autoencoder.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import boto3\n",
    "import tarfile\n",
    "import os\n",
    "import json\n",
    "import mlflow\n",
    "from time import gmtime, strftime\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, classification_report\n",
    "import io\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim=32, dropout_rate=0.2):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "def load_autoencoder_model(model_s3_path):\n",
    "    \"\"\"Load autoencoder model from S3\"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # Parse S3 path\n",
    "    s3_parts = model_s3_path.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "    bucket = s3_parts[0]\n",
    "    key = s3_parts[1]\n",
    "    \n",
    "    # Download model artifacts\n",
    "    local_model_path = '/tmp/model.tar.gz'\n",
    "    s3_client.download_file(bucket, key, local_model_path)\n",
    "    \n",
    "    # Extract model\n",
    "    extract_path = '/tmp/model'\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "    with tarfile.open(local_model_path, 'r:gz') as tar:\n",
    "        tar.extractall(path=extract_path)\n",
    "    \n",
    "    # Load model checkpoint - Fix for PyTorch 2.6+ weights_only issue\n",
    "    checkpoint = torch.load(os.path.join(extract_path, 'model.pth'), map_location='cpu', weights_only=False)\n",
    "    \n",
    "    # Create and load model\n",
    "    model = Autoencoder(\n",
    "        checkpoint['input_dim'],\n",
    "        checkpoint['encoding_dim'],\n",
    "        checkpoint['dropout_rate']\n",
    "    )\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "def evaluate_autoencoder(\n",
    "    test_x_data_s3_path,\n",
    "    test_y_data_s3_path,\n",
    "    model_s3_path,\n",
    "    output_s3_prefix,\n",
    "    tracking_server_arn,\n",
    "    experiment_name,\n",
    "    pipeline_run_id=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate autoencoder model for anomaly detection\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up MLflow\n",
    "    mlflow.set_tracking_uri(tracking_server_arn)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    run_name = f\"evaluate-autoencoder-{strftime('%d-%H-%M-%S', gmtime())}\"\n",
    "    if pipeline_run_id:\n",
    "        run_name = f\"evaluate-{pipeline_run_id}\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name, description=\"Autoencoder model evaluation\") as run:\n",
    "        \n",
    "        # Load test data\n",
    "        s3_client = boto3.client('s3')\n",
    "        \n",
    "        # Load test features\n",
    "        test_x_parts = test_x_data_s3_path.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "        test_x_local = '/tmp/test_features.csv'\n",
    "        s3_client.download_file(test_x_parts[0], test_x_parts[1], test_x_local)\n",
    "        test_features = pd.read_csv(test_x_local, header=None)\n",
    "        \n",
    "        # Load test targets\n",
    "        test_y_parts = test_y_data_s3_path.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "        test_y_local = '/tmp/test_targets.csv'\n",
    "        s3_client.download_file(test_y_parts[0], test_y_parts[1], test_y_local)\n",
    "        test_targets = pd.read_csv(test_y_local, header=None)[0].values\n",
    "        \n",
    "        print(f\"Loaded test data: {test_features.shape} features, {len(test_targets)} targets\")\n",
    "        \n",
    "        # Load model\n",
    "        model, checkpoint = load_autoencoder_model(model_s3_path)\n",
    "        threshold = checkpoint['threshold']\n",
    "        \n",
    "        print(f\"Loaded model with threshold: {threshold}\")\n",
    "        \n",
    "        # Make predictions\n",
    "        test_tensor = torch.FloatTensor(test_features.values)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            reconstructed = model(test_tensor)\n",
    "            reconstruction_errors = torch.mean((test_tensor - reconstructed) ** 2, dim=1).numpy()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        precision, recall, pr_thresholds = precision_recall_curve(test_targets, reconstruction_errors)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        \n",
    "        fpr, tpr, roc_thresholds = roc_curve(test_targets, reconstruction_errors)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Calculate F1 scores and find optimal threshold\n",
    "        f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
    "        optimal_idx = np.argmax(f1_scores)\n",
    "        optimal_threshold = pr_thresholds[optimal_idx]\n",
    "        max_f1_score = np.max(f1_scores)\n",
    "        \n",
    "        # Predictions using optimal threshold\n",
    "        predictions = (reconstruction_errors > optimal_threshold).astype(int)\n",
    "        \n",
    "        # Calculate confusion matrix components\n",
    "        tp = np.sum((test_targets == 1) & (predictions == 1))\n",
    "        fp = np.sum((test_targets == 0) & (predictions == 1))\n",
    "        tn = np.sum((test_targets == 0) & (predictions == 0))\n",
    "        fn = np.sum((test_targets == 1) & (predictions == 0))\n",
    "        \n",
    "        # Calculate additional metrics\n",
    "        precision_score = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall_score = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "        \n",
    "        # Create evaluation results\n",
    "        evaluation_result = {\n",
    "            \"anomaly_detection_metrics\": {\n",
    "                \"roc_auc\": {\"value\": float(roc_auc)},\n",
    "                \"pr_auc\": {\"value\": float(pr_auc)},\n",
    "                \"optimal_threshold\": {\"value\": float(optimal_threshold)},\n",
    "                \"max_f1_score\": {\"value\": float(max_f1_score)},\n",
    "                \"precision\": {\"value\": float(precision_score)},\n",
    "                \"recall\": {\"value\": float(recall_score)},\n",
    "                \"accuracy\": {\"value\": float(accuracy)},\n",
    "                \"true_positives\": {\"value\": int(tp)},\n",
    "                \"false_positives\": {\"value\": int(fp)},\n",
    "                \"true_negatives\": {\"value\": int(tn)},\n",
    "                \"false_negatives\": {\"value\": int(fn)},\n",
    "                \"mean_reconstruction_error\": {\"value\": float(np.mean(reconstruction_errors))},\n",
    "                \"std_reconstruction_error\": {\"value\": float(np.std(reconstruction_errors))}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Log metrics to MLflow\n",
    "        mlflow.log_metrics({\n",
    "            \"roc_auc\": roc_auc,\n",
    "            \"pr_auc\": pr_auc,\n",
    "            \"optimal_threshold\": optimal_threshold,\n",
    "            \"max_f1_score\": max_f1_score,\n",
    "            \"precision\": precision_score,\n",
    "            \"recall\": recall_score,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"mean_reconstruction_error\": np.mean(reconstruction_errors),\n",
    "            \"std_reconstruction_error\": np.std(reconstruction_errors)\n",
    "        })\n",
    "        \n",
    "        mlflow.set_tags({\n",
    "            'mlflow.source.type': 'JOB',\n",
    "            'model_type': 'autoencoder',\n",
    "            'step': 'evaluation'\n",
    "        })\n",
    "        \n",
    "        # Create prediction baseline for monitoring\n",
    "        prediction_baseline = pd.DataFrame({\n",
    "            'prediction': predictions,\n",
    "            'probability': reconstruction_errors,\n",
    "            'label': test_targets\n",
    "        })\n",
    "        \n",
    "        # Save prediction baseline\n",
    "        baseline_local = '/tmp/prediction_baseline.csv'\n",
    "        prediction_baseline.to_csv(baseline_local, index=False)\n",
    "        \n",
    "        # Upload to S3\n",
    "        output_bucket = output_s3_prefix.replace(\"s3://\", \"\").split(\"/\")[0]\n",
    "        output_prefix = \"/\".join(output_s3_prefix.replace(\"s3://\", \"\").split(\"/\")[1:])\n",
    "        \n",
    "        baseline_key = f\"{output_prefix}/prediction_baseline/prediction_baseline.csv\"\n",
    "        s3_client.upload_file(baseline_local, output_bucket, baseline_key)\n",
    "        prediction_baseline_s3_url = f\"s3://{output_bucket}/{baseline_key}\"\n",
    "        \n",
    "        # Save evaluation results\n",
    "        eval_results_local = '/tmp/evaluation.json'\n",
    "        with open(eval_results_local, 'w') as f:\n",
    "            json.dump(evaluation_result, f, indent=2)\n",
    "        \n",
    "        eval_key = f\"{output_prefix}/evaluation/evaluation.json\"\n",
    "        s3_client.upload_file(eval_results_local, output_bucket, eval_key)\n",
    "        \n",
    "        # Log artifacts\n",
    "        mlflow.log_artifact(baseline_local, \"prediction_baseline\")\n",
    "        mlflow.log_artifact(eval_results_local, \"evaluation\")\n",
    "        \n",
    "        print(f\"Evaluation completed. ROC AUC: {roc_auc:.4f}, PR AUC: {pr_auc:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'evaluation_result': evaluation_result,\n",
    "            'prediction_baseline_data': prediction_baseline_s3_url\n",
    "        }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--test-x-data-s3-path', type=str, required=True)\n",
    "    parser.add_argument('--test-y-data-s3-path', type=str, required=True)\n",
    "    parser.add_argument('--model-s3-path', type=str, required=True)\n",
    "    parser.add_argument('--output-s3-prefix', type=str, required=True)\n",
    "    parser.add_argument('--tracking-server-arn', type=str, required=True)\n",
    "    parser.add_argument('--experiment-name', type=str, required=True)\n",
    "    parser.add_argument('--pipeline-run-id', type=str, default=None)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    result = evaluate_autoencoder(\n",
    "        test_x_data_s3_path=args.test_x_data_s3_path,\n",
    "        test_y_data_s3_path=args.test_y_data_s3_path,\n",
    "        model_s3_path=args.model_s3_path,\n",
    "        output_s3_prefix=args.output_s3_prefix,\n",
    "        tracking_server_arn=args.tracking_server_arn,\n",
    "        experiment_name=args.experiment_name,\n",
    "        pipeline_run_id=args.pipeline_run_id\n",
    "    )\n",
    "    \n",
    "    print(f\"Evaluation result: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb4456-292e-4fc8-9a5f-b528d9ba9230",
   "metadata": {},
   "source": [
    "## The next code cell fits the estimator. Wait for the training job to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c375dad0-227d-46e1-b2a6-3e57779006df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:11:59.901499Z",
     "iopub.status.busy": "2025-08-06T09:11:59.901174Z",
     "iopub.status.idle": "2025-08-06T09:20:06.964094Z",
     "shell.execute_reply": "2025-08-06T09:20:06.963428Z",
     "shell.execute_reply.started": "2025-08-06T09:11:59.901477Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: from-idea-to-prod-autoencoder-train-2025-08-06-09-12-00-357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 09:12:01 Starting - Starting the training job...\n",
      "2025-08-06 09:12:22 Starting - Preparing the instances for training...\n",
      "2025-08-06 09:12:47 Downloading - Downloading input data...\n",
      "2025-08-06 09:13:12 Downloading - Downloading the training image...............\n",
      "2025-08-06 09:16:04 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2025-08-06 09:16:16,905 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2025-08-06 09:16:16,927 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-06 09:16:16,938 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2025-08-06 09:16:17,004 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2025-08-06 09:16:17,237 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.12.1+cu113)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision>=0.10.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.13.1+cu113)\u001b[0m\n",
      "\u001b[34mCollecting mlflow>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading mlflow-2.17.2-py3-none-any.whl (26.7 MB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 26.7/26.7 MB 54.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting sagemaker-mlflow>=0.1.0\u001b[0m\n",
      "\u001b[34mDownloading sagemaker_mlflow-0.1.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas>=1.3.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.5.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (4.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision>=0.10.0->-r requirements.txt (line 2)) (9.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision>=0.10.0->-r requirements.txt (line 2)) (2.28.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.8/site-packages (from mlflow>=2.0.0->-r requirements.txt (line 3)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.8/site-packages (from mlflow>=2.0.0->-r requirements.txt (line 3)) (3.7.0)\u001b[0m\n",
      "\u001b[34mCollecting Flask<4\u001b[0m\n",
      "\u001b[34mDownloading flask-3.0.3-py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 101.7/101.7 kB 29.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy<2 in /opt/conda/lib/python3.8/site-packages (from mlflow>=2.0.0->-r requirements.txt (line 3)) (1.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow<18,>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from mlflow>=2.0.0->-r requirements.txt (line 3)) (11.0.0)\u001b[0m\n",
      "\u001b[34mCollecting markdown<4,>=3.3\u001b[0m\n",
      "\u001b[34mDownloading Markdown-3.7-py3-none-any.whl (106 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 106.3/106.3 kB 36.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting alembic!=1.10.0,<2\u001b[0m\n",
      "\u001b[34mDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233.6/233.6 kB 53.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting mlflow-skinny==2.17.2\u001b[0m\n",
      "\u001b[34mDownloading mlflow_skinny-2.17.2-py3-none-any.whl (5.7 MB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.7/5.7 MB 110.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting docker<8,>=4.0.0\u001b[0m\n",
      "\u001b[34mDownloading docker-7.1.0-py3-none-any.whl (147 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 147.8/147.8 kB 46.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting sqlalchemy<3,>=1.4.0\u001b[0m\n",
      "\u001b[34mDownloading sqlalchemy-2.0.42-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3.2/3.2 MB 130.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting gunicorn<24\u001b[0m\n",
      "\u001b[34mDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 85.0/85.0 kB 29.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting graphene<4\u001b[0m\n",
      "\u001b[34mDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 114.9/114.9 kB 39.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<6,>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from mlflow-skinny==2.17.2->mlflow>=2.0.0->-r requirements.txt (line 3)) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting opentelemetry-sdk<3,>=1.9.0\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 119.0/119.0 kB 41.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6,>=5.0.0\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting sqlparse<1,>=0.4.0\u001b[0m\n",
      "\u001b[34mDownloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 44.4/44.4 kB 17.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /opt/conda/lib/python3.8/site-packages (from mlflow-skinny==2.17.2->mlflow>=2.0.0->-r requirements.txt (line 3)) (4.13.0)\u001b[0m\n",
      "\u001b[34mCollecting databricks-sdk<1,>=0.20.0\u001b[0m\n",
      "\u001b[34mDownloading databricks_sdk-0.61.0-py3-none-any.whl (680 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 680.6/680.6 kB 100.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting gitpython<4,>=3.1.9\u001b[0m\n",
      "\u001b[34mDownloading gitpython-3.1.45-py3-none-any.whl (208 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208.2/208.2 kB 56.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.8/site-packages (from mlflow-skinny==2.17.2->mlflow>=2.0.0->-r requirements.txt (line 3)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.8/site-packages (from mlflow-skinny==2.17.2->mlflow>=2.0.0->-r requirements.txt (line 3)) (2.2.1)\u001b[0m\n",
      "\u001b[34mCollecting opentelemetry-api<3,>=1.9.0\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65.8/65.8 kB 23.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.8/site-packages (from mlflow-skinny==2.17.2->mlflow>=2.0.0->-r requirements.txt (line 3)) (8.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging<25 in /opt/conda/lib/python3.8/site-packages (from mlflow-skinny==2.17.2->mlflow>=2.0.0->-r requirements.txt (line 3)) (23.0)\u001b[0m\n",
      "\u001b[34mCollecting boto3>=1.34\u001b[0m\n",
      "\u001b[34mDownloading boto3-1.37.38-py3-none-any.whl (139 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 139.9/139.9 kB 43.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 5)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 5)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.3.0->-r requirements.txt (line 6)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.3.0->-r requirements.txt (line 6)) (2022.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.8/site-packages (from alembic!=1.10.0,<2->mlflow>=2.0.0->-r requirements.txt (line 3)) (5.10.2)\u001b[0m\n",
      "\u001b[34mCollecting Mako\u001b[0m\n",
      "\u001b[34mDownloading mako-1.3.10-py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 78.5/78.5 kB 28.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting s3transfer<0.12.0,>=0.11.0\u001b[0m\n",
      "\u001b[34mDownloading s3transfer-0.11.5-py3-none-any.whl (84 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 84.8/84.8 kB 33.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3>=1.34->sagemaker-mlflow>=0.1.0->-r requirements.txt (line 4)) (1.0.1)\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.38.0,>=1.37.38\u001b[0m\n",
      "\u001b[34mDownloading botocore-1.37.38-py3-none-any.whl (13.5 MB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13.5/13.5 MB 114.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.8/site-packages (from docker<8,>=4.0.0->mlflow>=2.0.0->-r requirements.txt (line 3)) (1.26.14)\u001b[0m\n",
      "\u001b[34mCollecting Werkzeug>=3.0.0\u001b[0m\n",
      "\u001b[34mDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 228.0/228.0 kB 58.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting itsdangerous>=2.1.2\u001b[0m\n",
      "\u001b[34mDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mCollecting blinker>=1.6.2\u001b[0m\n",
      "\u001b[34mDownloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting graphql-relay<3.3,>=3.1\u001b[0m\n",
      "\u001b[34mDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mCollecting graphql-core<3.3,>=3.1\u001b[0m\n",
      "\u001b[34mDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 203.4/203.4 kB 55.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting typing-extensions\u001b[0m\n",
      "\u001b[34mDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45.8/45.8 kB 18.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from Jinja2<4,>=2.11->mlflow>=2.0.0->-r requirements.txt (line 3)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib<4->mlflow>=2.0.0->-r requirements.txt (line 3)) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib<4->mlflow>=2.0.0->-r requirements.txt (line 3)) (1.0.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib<4->mlflow>=2.0.0->-r requirements.txt (line 3)) (4.38.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib<4->mlflow>=2.0.0->-r requirements.txt (line 3)) (1.4.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib<4->mlflow>=2.0.0->-r requirements.txt (line 3)) (0.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=1.3.0->-r requirements.txt (line 6)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision>=0.10.0->-r requirements.txt (line 2)) (2022.12.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision>=0.10.0->-r requirements.txt (line 2)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision>=0.10.0->-r requirements.txt (line 2)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.8/site-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.0.0->-r requirements.txt (line 3)) (2.0.2)\u001b[0m\n",
      "\u001b[34mCollecting google-auth~=2.0\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 216.1/216.1 kB 57.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.12-py3-none-any.whl (62 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 62.8/62.8 kB 22.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.2->mlflow>=2.0.0->-r requirements.txt (line 3)) (3.13.0)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata!=4.7.0,<9,>=3.7.0\u001b[0m\n",
      "\u001b[34mDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\u001b[0m\n",
      "\u001b[34mCollecting deprecated>=1.2.6\u001b[0m\n",
      "\u001b[34mDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting zipp>=0.5\u001b[0m\n",
      "\u001b[34mDownloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting opentelemetry-semantic-conventions==0.54b1\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 194.9/194.9 kB 55.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting wrapt<2,>=1.10\u001b[0m\n",
      "\u001b[34mDownloading wrapt-1.17.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 85.6/85.6 kB 30.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 181.3/181.3 kB 50.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow>=2.0.0->-r requirements.txt (line 3)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1<0.7.0,>=0.6.1\u001b[0m\n",
      "\u001b[34mDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\u001b[0m\n",
      "\u001b[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 83.1/83.1 kB 29.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: zipp, wrapt, Werkzeug, typing-extensions, sqlparse, smmap, pyasn1, Mako, itsdangerous, gunicorn, cachetools, blinker, sqlalchemy, pyasn1-modules, importlib-metadata, graphql-core, gitdb, docker, deprecated, botocore, s3transfer, opentelemetry-api, markdown, graphql-relay, google-auth, gitpython, Flask, alembic, opentelemetry-semantic-conventions, graphene, databricks-sdk, boto3, opentelemetry-sdk, mlflow-skinny, mlflow, sagemaker-mlflow\u001b[0m\n",
      "\u001b[34mAttempting uninstall: zipp\u001b[0m\n",
      "\u001b[34mFound existing installation: zipp 3.13.0\u001b[0m\n",
      "\u001b[34mUninstalling zipp-3.13.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled zipp-3.13.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: Werkzeug\u001b[0m\n",
      "\u001b[34mFound existing installation: Werkzeug 2.2.3\u001b[0m\n",
      "\u001b[34mUninstalling Werkzeug-2.2.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled Werkzeug-2.2.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: typing-extensions\u001b[0m\n",
      "\u001b[34mFound existing installation: typing_extensions 4.4.0\u001b[0m\n",
      "\u001b[34mUninstalling typing_extensions-4.4.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled typing_extensions-4.4.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: pyasn1\u001b[0m\n",
      "\u001b[34mFound existing installation: pyasn1 0.4.8\u001b[0m\n",
      "\u001b[34mUninstalling pyasn1-0.4.8:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled pyasn1-0.4.8\u001b[0m\n",
      "\u001b[34mAttempting uninstall: importlib-metadata\u001b[0m\n",
      "\u001b[34mFound existing installation: importlib-metadata 4.13.0\u001b[0m\n",
      "\u001b[34mUninstalling importlib-metadata-4.13.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled importlib-metadata-4.13.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: botocore\u001b[0m\n",
      "\u001b[34mFound existing installation: botocore 1.29.70\u001b[0m\n",
      "\u001b[34mUninstalling botocore-1.29.70:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled botocore-1.29.70\u001b[0m\n",
      "\u001b[34mAttempting uninstall: s3transfer\u001b[0m\n",
      "\u001b[34mFound existing installation: s3transfer 0.6.0\u001b[0m\n",
      "\u001b[34mUninstalling s3transfer-0.6.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled s3transfer-0.6.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: boto3\u001b[0m\n",
      "\u001b[34mFound existing installation: boto3 1.26.70\u001b[0m\n",
      "\u001b[34mUninstalling boto3-1.26.70:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled boto3-1.26.70\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker 2.132.0 requires importlib-metadata<5.0,>=1.4.0, but you have importlib-metadata 8.5.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mawscli 1.27.70 requires botocore==1.29.70, but you have botocore 1.37.38 which is incompatible.\u001b[0m\n",
      "\u001b[34mawscli 1.27.70 requires s3transfer<0.7.0,>=0.6.0, but you have s3transfer 0.11.5 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed Flask-3.0.3 Mako-1.3.10 Werkzeug-3.0.6 alembic-1.14.1 blinker-1.8.2 boto3-1.37.38 botocore-1.37.38 cachetools-5.5.2 databricks-sdk-0.61.0 deprecated-1.2.18 docker-7.1.0 gitdb-4.0.12 gitpython-3.1.45 google-auth-2.40.3 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 importlib-metadata-8.5.0 itsdangerous-2.2.0 markdown-3.7 mlflow-2.17.2 mlflow-skinny-2.17.2 opentelemetry-api-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 pyasn1-0.6.1 pyasn1-modules-0.4.2 s3transfer-0.11.5 sagemaker-mlflow-0.1.0 smmap-5.0.2 sqlalchemy-2.0.42 sqlparse-0.5.3 typing-extensions-4.13.2 wrapt-1.17.2 zipp-3.20.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.0 -> 25.0.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2025-08-06 09:16:33,177 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-08-06 09:16:33,177 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-08-06 09:16:33,220 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-06 09:16:33,255 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-06 09:16:33,292 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-06 09:16:33,304 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": \"64\",\n",
      "        \"dropout_rate\": \"0.2\",\n",
      "        \"encoding_dim\": \"32\",\n",
      "        \"learning_rate\": \"0.001\",\n",
      "        \"num_epochs\": \"100\",\n",
      "        \"weight_decay\": \"1e-05\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"from-idea-to-prod-autoencoder-train-2025-08-06-09-12-00-357\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-224425919845/from-idea-to-prod-autoencoder-train-2025-08-06-09-12-00-357/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_autoencoder\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train_autoencoder.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":\"64\",\"dropout_rate\":\"0.2\",\"encoding_dim\":\"32\",\"learning_rate\":\"0.001\",\"num_epochs\":\"100\",\"weight_decay\":\"1e-05\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_autoencoder.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_autoencoder\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-224425919845/from-idea-to-prod-autoencoder-train-2025-08-06-09-12-00-357/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":\"64\",\"dropout_rate\":\"0.2\",\"encoding_dim\":\"32\",\"learning_rate\":\"0.001\",\"num_epochs\":\"100\",\"weight_decay\":\"1e-05\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"from-idea-to-prod-autoencoder-train-2025-08-06-09-12-00-357\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-224425919845/from-idea-to-prod-autoencoder-train-2025-08-06-09-12-00-357/source/sourcedir.tar.gz\",\"module_name\":\"train_autoencoder\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train_autoencoder.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"64\",\"--dropout_rate\",\"0.2\",\"--encoding_dim\",\"32\",\"--learning_rate\",\"0.001\",\"--num_epochs\",\"100\",\"--weight_decay\",\"1e-05\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT_RATE=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_ENCODING_DIM=32\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_EPOCHS=100\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=1e-05\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg:/opt/conda/lib/python3.8/site-packages/flash_attn-0.1-py3.8-linux-x86_64.egg:/opt/conda/lib/python3.8/site-packages/einops-0.6.0-py3.8.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 train_autoencoder.py --batch_size 64 --dropout_rate 0.2 --encoding_dim 32 --learning_rate 0.001 --num_epochs 100 --weight_decay 1e-05\u001b[0m\n",
      "\u001b[34m2025-08-06 09:16:35,849 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m[2025-08-06 09:16:43.158 algo-1:92 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2025-08-06 09:16:43.300 algo-1:92 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2025-08-06 09:16:43.301 algo-1:92 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2025-08-06 09:16:43.302 algo-1:92 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2025-08-06 09:16:43.302 algo-1:92 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2025-08-06 09:16:43.303 algo-1:92 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mDownloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mDownloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 5146.39it/s]\u001b[0m\n",
      "\u001b[34mDownloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 2534.32it/s]\u001b[0m\n",
      "\u001b[34m2025/08/06 09:19:10 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\u001b[0m\n",
      "\u001b[34m2025/08/06 09:19:15 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\u001b[0m\n",
      "\u001b[34m2025/08/06 09:19:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\u001b[34m2025/08/06 09:19:15 INFO mlflow.tracking._tracking_service.client: üèÉ View run autoencoder-training-06-09-16-37 at: https://us-west-2.experiments.sagemaker.aws/#/experiments/55/runs/81f0e146f09745bfb523cbae6361ede7.\u001b[0m\n",
      "\u001b[34m2025/08/06 09:19:15 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://us-west-2.experiments.sagemaker.aws/#/experiments/55.\u001b[0m\n",
      "\u001b[34m2025-08-06 09:19:16,736 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-08-06 09:19:16,736 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-08-06 09:19:16,737 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-08-06 09:19:38 Uploading - Uploading generated training model\n",
      "2025-08-06 09:19:38 Completed - Training job completed\n",
      "Training seconds: 411\n",
      "Billable seconds: 411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.analytics:Warning: No metrics called train_loss found\n",
      "WARNING:sagemaker.analytics:Warning: No metrics called val_loss found\n",
      "WARNING:sagemaker.analytics:Warning: No metrics called reconstruction_threshold found\n",
      "2025/08/06 09:20:06 WARNING mlflow.utils.requirements_utils: Found triton version (3.2.0+git576374f8) contains a local version label (+git576374f8). MLflow logged a pip requirement for this package as 'triton==3.2.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/08/06 09:20:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run autoencoder-training-06-09-12-00 at: https://us-west-2.experiments.sagemaker.aws/#/experiments/56/runs/ff6464d38ef44e9aaa2ce7a85c068bd8\n",
      "üß™ View experiment at: https://us-west-2.experiments.sagemaker.aws/#/experiments/56\n"
     ]
    }
   ],
   "source": [
    "from pipeline_steps.evaluate_autoencoder import load_autoencoder_model\n",
    "mlflow.set_experiment(r_preprocess['experiment_name'])\n",
    "with mlflow.start_run(\n",
    "    run_name=f\"autoencoder-training-{strftime('%d-%H-%M-%S', gmtime())}\",\n",
    "    description=\"autoencoder training in the notebook 03 with a training job\") as run:\n",
    "    mlflow.log_params(estimator.hyperparameters())\n",
    "    \n",
    "    estimator.fit(training_inputs)\n",
    "\n",
    "    mlflow.log_param(\"training job name\", estimator.latest_training_job.name)\n",
    "    mlflow.log_metrics({i['metric_name'].replace(':', '_'):i['value'] for i in estimator.training_job_analytics.dataframe().iloc})\n",
    "    mlflow.pytorch.log_model(load_autoencoder_model(estimator.model_data)[0], artifact_path=\"autoencoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c48f023-fcde-4eda-bc29-a8bb9638b224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:24:27.871215Z",
     "iopub.status.busy": "2025-08-06T09:24:27.870922Z",
     "iopub.status.idle": "2025-08-06T09:24:28.948809Z",
     "shell.execute_reply": "2025-08-06T09:24:28.948025Z",
     "shell.execute_reply.started": "2025-08-06T09:24:27.871194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 09:19:31     143107 model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {estimator.model_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6a77cc0-4e45-49b5-85ea-bb3f5c871371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:24:50.255189Z",
     "iopub.status.busy": "2025-08-06T09:24:50.254732Z",
     "iopub.status.idle": "2025-08-06T09:24:51.547860Z",
     "shell.execute_reply": "2025-08-06T09:24:51.547350Z",
     "shell.execute_reply.started": "2025-08-06T09:24:50.255168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test data: (6179, 64) features, 6179 targets\n",
      "Loaded model with threshold: 0.13681658655405043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/amazon-sagemaker-from-idea-to-production/trendmicro_workshop/pipeline_steps/evaluate_autoencoder.py:143: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed. ROC AUC: 0.6765, PR AUC: 0.2590\n",
      "üèÉ View run evaluate-autoencoder-06-09-24-50 at: https://us-west-2.experiments.sagemaker.aws/#/experiments/56/runs/8295d1a6976145f096d320ac88d34f8c\n",
      "üß™ View experiment at: https://us-west-2.experiments.sagemaker.aws/#/experiments/56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'evaluation_result': {'anomaly_detection_metrics': {'roc_auc': {'value': 0.6765062665196033},\n",
       "   'pr_auc': {'value': 0.25897085378591583},\n",
       "   'optimal_threshold': {'value': 2.501936912536621},\n",
       "   'max_f1_score': {'value': nan},\n",
       "   'precision': {'value': 0.0},\n",
       "   'recall': {'value': 0.0},\n",
       "   'accuracy': {'value': 0.8876840912769056},\n",
       "   'true_positives': {'value': 0},\n",
       "   'false_positives': {'value': 2},\n",
       "   'true_negatives': {'value': 5485},\n",
       "   'false_negatives': {'value': 692},\n",
       "   'mean_reconstruction_error': {'value': 0.043993186205625534},\n",
       "   'std_reconstruction_error': {'value': 0.14815062284469604}}},\n",
       " 'prediction_baseline_data': 's3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/prediction_baseline/prediction_baseline.csv'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipeline_steps.evaluate_autoencoder import evaluate_autoencoder\n",
    "r_eval = evaluate_autoencoder(\n",
    "    test_x_data_s3_path=r_preprocess['test_x_data'],\n",
    "    test_y_data_s3_path=r_preprocess['test_y_data'],\n",
    "    model_s3_path=estimator.model_data,\n",
    "    output_s3_prefix=output_s3_prefix,\n",
    "    tracking_server_arn=mlflow_arn,\n",
    "    experiment_name=r_preprocess['experiment_name'],\n",
    ")\n",
    "r_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "549119d1-3a69-4826-9bb4-fe4234a97cba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:25:21.942479Z",
     "iopub.status.busy": "2025-08-06T09:25:21.942151Z",
     "iopub.status.idle": "2025-08-06T09:25:22.905956Z",
     "shell.execute_reply": "2025-08-06T09:25:22.905160Z",
     "shell.execute_reply.started": "2025-08-06T09:25:21.942456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-06 09:24:52      99347 prediction_baseline.csv\n"
     ]
    }
   ],
   "source": [
    "# check that the evaluation function generated output\n",
    "!aws s3 ls {output_s3_prefix}/prediction_baseline/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fccb162-0abb-40b7-8898-c002b71087c1",
   "metadata": {},
   "source": [
    "#### Model registration step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d8a9cbb-3636-4667-a026-f1f4118c88b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:26:23.763657Z",
     "iopub.status.busy": "2025-08-06T09:26:23.763319Z",
     "iopub.status.idle": "2025-08-06T09:26:23.820692Z",
     "shell.execute_reply": "2025-08-06T09:26:23.820125Z",
     "shell.execute_reply.started": "2025-08-06T09:26:23.763631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline_steps/register_autoencoder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline_steps/register_autoencoder.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import mlflow\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "\n",
    "def register_autoencoder(\n",
    "    training_job_name,\n",
    "    model_package_group_name,\n",
    "    model_approval_status,\n",
    "    evaluation_result,\n",
    "    output_s3_prefix,\n",
    "    tracking_server_arn,\n",
    "    experiment_name,\n",
    "    pipeline_run_id=None,\n",
    "    model_statistics_s3_path=None,\n",
    "    model_constraints_s3_path=None,\n",
    "    model_data_statistics_s3_path=None,\n",
    "    model_data_constraints_s3_path=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Register autoencoder model in SageMaker Model Registry\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up MLflow\n",
    "    mlflow.set_tracking_uri(tracking_server_arn)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    run_name = f\"register-autoencoder-{strftime('%d-%H-%M-%S', gmtime())}\"\n",
    "    if pipeline_run_id:\n",
    "        run_name = f\"register-{pipeline_run_id}\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name, description=\"Autoencoder model registration\") as run:\n",
    "        \n",
    "        # Get SageMaker client\n",
    "        sm_client = boto3.client('sagemaker')\n",
    "        \n",
    "        # Ensure Model Package Group exists with proper tags\n",
    "        try:\n",
    "            # Check if model package group exists\n",
    "            sm_client.describe_model_package_group(ModelPackageGroupName=model_package_group_name)\n",
    "            print(f\"Model Package Group {model_package_group_name} already exists\")\n",
    "        except sm_client.exceptions.ClientError as e:\n",
    "            if e.response['Error']['Code'] == 'ValidationException':\n",
    "                # Model Package Group doesn't exist, create it with tags\n",
    "                print(f\"Creating Model Package Group: {model_package_group_name}\")\n",
    "                sm_client.create_model_package_group(\n",
    "                    ModelPackageGroupName=model_package_group_name,\n",
    "                    ModelPackageGroupDescription=f\"PyTorch autoencoder models for anomaly detection\",\n",
    "                    Tags=[\n",
    "                        {\"Key\": \"ModelType\", \"Value\": \"Autoencoder\"},\n",
    "                        {\"Key\": \"Framework\", \"Value\": \"PyTorch\"},\n",
    "                        {\"Key\": \"UseCase\", \"Value\": \"AnomalyDetection\"},\n",
    "                        {\"Key\": \"Project\", \"Value\": \"from-idea-to-prod\"}\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                raise e\n",
    "        \n",
    "        # Get training job details\n",
    "        training_job = sm_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "        model_data_url = training_job['ModelArtifacts']['S3ModelArtifacts']\n",
    "        \n",
    "        # Create model metrics\n",
    "        model_metrics = None\n",
    "        if evaluation_result:\n",
    "            # Save evaluation metrics to S3\n",
    "            s3_client = boto3.client('s3')\n",
    "            output_bucket = output_s3_prefix.replace(\"s3://\", \"\").split(\"/\")[0]\n",
    "            output_prefix = \"/\".join(output_s3_prefix.replace(\"s3://\", \"\").split(\"/\")[1:])\n",
    "            \n",
    "            metrics_local = '/tmp/model_metrics.json'\n",
    "            with open(metrics_local, 'w') as f:\n",
    "                json.dump(evaluation_result, f, indent=2)\n",
    "            \n",
    "            metrics_key = f\"{output_prefix}/model_metrics/model_metrics.json\"\n",
    "            s3_client.upload_file(metrics_local, output_bucket, metrics_key)\n",
    "            metrics_s3_url = f\"s3://{output_bucket}/{metrics_key}\"\n",
    "            \n",
    "            model_metrics = ModelMetrics(\n",
    "                model_statistics=MetricsSource(\n",
    "                    s3_uri=metrics_s3_url,\n",
    "                    content_type=\"application/json\"\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Create drift check baselines if provided\n",
    "        drift_check_baselines = None\n",
    "        if any([model_statistics_s3_path, model_constraints_s3_path, \n",
    "                model_data_statistics_s3_path, model_data_constraints_s3_path]):\n",
    "            drift_check_baselines = DriftCheckBaselines(\n",
    "                model_statistics=MetricsSource(\n",
    "                    s3_uri=model_statistics_s3_path,\n",
    "                    content_type=\"application/json\"\n",
    "                ) if model_statistics_s3_path else None,\n",
    "                model_constraints=MetricsSource(\n",
    "                    s3_uri=model_constraints_s3_path,\n",
    "                    content_type=\"application/json\"\n",
    "                ) if model_constraints_s3_path else None,\n",
    "                model_data_statistics=MetricsSource(\n",
    "                    s3_uri=model_data_statistics_s3_path,\n",
    "                    content_type=\"application/json\"\n",
    "                ) if model_data_statistics_s3_path else None,\n",
    "                model_data_constraints=MetricsSource(\n",
    "                    s3_uri=model_data_constraints_s3_path,\n",
    "                    content_type=\"application/json\"\n",
    "                ) if model_data_constraints_s3_path else None,\n",
    "            )\n",
    "        \n",
    "        # Get execution role\n",
    "        execution_role = training_job['RoleArn']\n",
    "        \n",
    "        # Get container image\n",
    "        container_image = training_job['AlgorithmSpecification']['TrainingImage']\n",
    "        \n",
    "        # Create model package (without tags - tags go on the group, not individual versions)\n",
    "        model_package_input_dict = {\n",
    "            \"ModelPackageGroupName\": model_package_group_name,\n",
    "            \"ModelPackageDescription\": f\"PyTorch autoencoder for anomaly detection. Training job: {training_job_name}\",\n",
    "            \"ModelApprovalStatus\": model_approval_status,\n",
    "            \"InferenceSpecification\": {\n",
    "                \"Containers\": [\n",
    "                    {\n",
    "                        \"Image\": container_image,\n",
    "                        \"ModelDataUrl\": model_data_url,\n",
    "                        \"Framework\": \"PYTORCH\",\n",
    "                        \"FrameworkVersion\": \"1.12\"\n",
    "                    }\n",
    "                ],\n",
    "                \"SupportedContentTypes\": [\"text/csv\"],\n",
    "                \"SupportedResponseMIMETypes\": [\"application/json\"],\n",
    "                \"SupportedRealtimeInferenceInstanceTypes\": [\n",
    "                    \"ml.t2.medium\",\n",
    "                    \"ml.m5.large\",\n",
    "                    \"ml.m5.xlarge\"\n",
    "                ],\n",
    "                \"SupportedTransformInstanceTypes\": [\n",
    "                    \"ml.m5.large\",\n",
    "                    \"ml.m5.xlarge\"\n",
    "                ]\n",
    "            }\n",
    "            # Note: Tags removed - they should be on the Model Package Group, not individual versions\n",
    "        }\n",
    "        \n",
    "        # Add model metrics if available\n",
    "        if model_metrics:\n",
    "            model_package_input_dict[\"ModelMetrics\"] = {\n",
    "                \"ModelQuality\": {\n",
    "                    \"Statistics\": {\n",
    "                        \"ContentType\": \"application/json\",\n",
    "                        \"S3Uri\": metrics_s3_url\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Add drift check baselines if available\n",
    "        if drift_check_baselines:\n",
    "            model_package_input_dict[\"DriftCheckBaselines\"] = drift_check_baselines.to_request()\n",
    "        \n",
    "        # Create model package\n",
    "        try:\n",
    "            response = sm_client.create_model_package(**model_package_input_dict)\n",
    "            model_package_arn = response['ModelPackageArn']\n",
    "            \n",
    "            print(f\"‚úÖ Model package created: {model_package_arn}\")\n",
    "            \n",
    "            # Log to MLflow\n",
    "            mlflow.log_params({\n",
    "                \"model_package_group_name\": model_package_group_name,\n",
    "                \"model_approval_status\": model_approval_status,\n",
    "                \"training_job_name\": training_job_name\n",
    "            })\n",
    "            \n",
    "            if evaluation_result and 'anomaly_detection_metrics' in evaluation_result:\n",
    "                metrics = evaluation_result['anomaly_detection_metrics']\n",
    "                mlflow.log_metrics({\n",
    "                    \"registered_model_roc_auc\": metrics.get('roc_auc', {}).get('value', 0),\n",
    "                    \"registered_model_pr_auc\": metrics.get('pr_auc', {}).get('value', 0),\n",
    "                    \"registered_model_f1_score\": metrics.get('max_f1_score', {}).get('value', 0)\n",
    "                })\n",
    "            \n",
    "            mlflow.set_tags({\n",
    "                'mlflow.source.type': 'JOB',\n",
    "                'model_type': 'autoencoder',\n",
    "                'step': 'registration',\n",
    "                'model_package_arn': model_package_arn\n",
    "            })\n",
    "            \n",
    "            return {\n",
    "                'model_package_arn': model_package_arn,\n",
    "                'model_package_group_name': model_package_group_name,\n",
    "                'model_approval_status': model_approval_status\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error creating model package: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--training-job-name', type=str, required=True)\n",
    "    parser.add_argument('--model-package-group-name', type=str, required=True)\n",
    "    parser.add_argument('--model-approval-status', type=str, required=True)\n",
    "    parser.add_argument('--evaluation-result', type=str, required=True)\n",
    "    parser.add_argument('--output-s3-prefix', type=str, required=True)\n",
    "    parser.add_argument('--tracking-server-arn', type=str, required=True)\n",
    "    parser.add_argument('--experiment-name', type=str, required=True)\n",
    "    parser.add_argument('--pipeline-run-id', type=str, default=None)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Parse evaluation result from JSON string\n",
    "    evaluation_result = json.loads(args.evaluation_result)\n",
    "    \n",
    "    result = register_autoencoder(\n",
    "        training_job_name=args.training_job_name,\n",
    "        model_package_group_name=args.model_package_group_name,\n",
    "        model_approval_status=args.model_approval_status,\n",
    "        evaluation_result=evaluation_result,\n",
    "        output_s3_prefix=args.output_s3_prefix,\n",
    "        tracking_server_arn=args.tracking_server_arn,\n",
    "        experiment_name=args.experiment_name,\n",
    "        pipeline_run_id=args.pipeline_run_id\n",
    "    )\n",
    "    \n",
    "    print(f\"Registration result: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4faffe3-dd86-45eb-99d4-63d2782a8aa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:26:25.232378Z",
     "iopub.status.busy": "2025-08-06T09:26:25.232062Z",
     "iopub.status.idle": "2025-08-06T09:26:25.285324Z",
     "shell.execute_reply": "2025-08-06T09:26:25.284671Z",
     "shell.execute_reply.started": "2025-08-06T09:26:25.232356Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pipeline_steps.register_autoencoder import register_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41069a43-dda9-4ca7-93db-51ff29743ce9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:26:26.555223Z",
     "iopub.status.busy": "2025-08-06T09:26:26.554845Z",
     "iopub.status.idle": "2025-08-06T09:26:27.765734Z",
     "shell.execute_reply": "2025-08-06T09:26:27.765175Z",
     "shell.execute_reply.started": "2025-08-06T09:26:26.555198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model Package Group: from-idea-to-prod-autoencoder-pipeline-model-06-08-50-22\n",
      "‚úÖ Model package created: arn:aws:sagemaker:us-west-2:224425919845:model-package/from-idea-to-prod-autoencoder-pipeline-model-06-08-50-22/1\n",
      "üèÉ View run register-autoencoder-06-09-26-26 at: https://us-west-2.experiments.sagemaker.aws/#/experiments/56/runs/d35ec0bf13fd4144950207663dd744be\n",
      "üß™ View experiment at: https://us-west-2.experiments.sagemaker.aws/#/experiments/56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_package_arn': 'arn:aws:sagemaker:us-west-2:224425919845:model-package/from-idea-to-prod-autoencoder-pipeline-model-06-08-50-22/1',\n",
       " 'model_package_group_name': 'from-idea-to-prod-autoencoder-pipeline-model-06-08-50-22',\n",
       " 'model_approval_status': 'PendingManualApproval'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_register = register_autoencoder(\n",
    "    training_job_name=estimator.latest_training_job.name,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_approval_status=model_approval_status,\n",
    "    evaluation_result=r_eval['evaluation_result'],\n",
    "    output_s3_prefix=output_s3_url,\n",
    "    tracking_server_arn=mlflow_arn,\n",
    "    experiment_name=r_preprocess['experiment_name'],\n",
    ")\n",
    "r_register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65aaf7f7-d114-4eac-b601-e3bf1bdee044",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:26:57.445021Z",
     "iopub.status.busy": "2025-08-06T09:26:57.444741Z",
     "iopub.status.idle": "2025-08-06T09:26:57.590912Z",
     "shell.execute_reply": "2025-08-06T09:26:57.590359Z",
     "shell.execute_reply.started": "2025-08-06T09:26:57.445001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelPackageGroupName': 'from-idea-to-prod-autoencoder-pipeline-model-06-08-50-22',\n",
       " 'ModelPackageVersion': 1,\n",
       " 'ModelPackageArn': 'arn:aws:sagemaker:us-west-2:224425919845:model-package/from-idea-to-prod-autoencoder-pipeline-model-06-08-50-22/1',\n",
       " 'ModelPackageDescription': 'PyTorch autoencoder for anomaly detection. Training job: from-idea-to-prod-autoencoder-train-2025-08-06-09-12-00-357',\n",
       " 'CreationTime': datetime.datetime(2025, 8, 6, 9, 26, 27, 431000, tzinfo=tzlocal()),\n",
       " 'InferenceSpecification': {'Containers': [{'Image': '763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:1.12-gpu-py38',\n",
       "    'ImageDigest': 'sha256:71b4ded5aac900d117824923fa93a6e626bed538fcae7282dcfdcbe7a752e3eb',\n",
       "    'ModelDataUrl': 's3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/output/from-idea-to-prod-autoencoder-train-2025-08-06-09-12-00-357/output/model.tar.gz',\n",
       "    'Framework': 'PYTORCH',\n",
       "    'FrameworkVersion': '1.12',\n",
       "    'ModelDataETag': 'b38c7e78a1ed0a2a96c2e14a01370818'}],\n",
       "  'SupportedTransformInstanceTypes': ['ml.m5.large', 'ml.m5.xlarge'],\n",
       "  'SupportedRealtimeInferenceInstanceTypes': ['ml.t2.medium',\n",
       "   'ml.m5.large',\n",
       "   'ml.m5.xlarge'],\n",
       "  'SupportedContentTypes': ['text/csv'],\n",
       "  'SupportedResponseMIMETypes': ['application/json']},\n",
       " 'ModelPackageStatus': 'Completed',\n",
       " 'ModelPackageStatusDetails': {'ValidationStatuses': [],\n",
       "  'ImageScanStatuses': []},\n",
       " 'CertifyForMarketplace': False,\n",
       " 'ModelApprovalStatus': 'PendingManualApproval',\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-west-2:224425919845:user-profile/d-rtctvdud9qsp/studio-user-7788a530',\n",
       "  'UserProfileName': 'studio-user-7788a530',\n",
       "  'DomainId': 'd-rtctvdud9qsp',\n",
       "  'IamIdentity': {'Arn': 'arn:aws:sts::224425919845:assumed-role/tm-ws-SageMakerExecutionRole-Ou4AK8i38tA1/SageMaker',\n",
       "   'PrincipalId': 'AROATIQGTYVSVCQU4RTXO:SageMaker'}},\n",
       " 'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
       "    'S3Uri': 's3://sagemaker-us-west-2-224425919845/from-idea-to-prod/autoencoder/output/model_metrics/model_metrics.json'}}},\n",
       " 'ResponseMetadata': {'RequestId': 'eff833ba-3abc-48cd-9b76-a699bfdfb6c6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'eff833ba-3abc-48cd-9b76-a699bfdfb6c6',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1889',\n",
       "   'date': 'Wed, 06 Aug 2025 09:26:57 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that a new model version has been registered in the model package group\n",
    "boto3.client('sagemaker').describe_model_package(ModelPackageName=r_register['model_package_arn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f1db8e-4a19-409e-90ad-46e9f03993c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:27:16.802449Z",
     "iopub.status.busy": "2025-08-06T09:27:16.802095Z",
     "iopub.status.idle": "2025-08-06T09:27:16.853995Z",
     "shell.execute_reply": "2025-08-06T09:27:16.853425Z",
     "shell.execute_reply.started": "2025-08-06T09:27:16.802425Z"
    }
   },
   "source": [
    "### Construct a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf6dd7a0-cfd2-4b19-ade6-0c05fd80a605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:27:47.468410Z",
     "iopub.status.busy": "2025-08-06T09:27:47.467991Z",
     "iopub.status.idle": "2025-08-06T09:27:49.694610Z",
     "shell.execute_reply": "2025-08-06T09:27:49.694100Z",
     "shell.execute_reply.started": "2025-08-06T09:27:47.468389Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "/opt/conda/lib/python3.12/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# preprocess data step\n",
    "step_preprocess = step(\n",
    "    preprocess_autoencoder, \n",
    "    instance_type=process_instance_type_param,\n",
    "    name=f\"{project}-preprocess\",\n",
    "    keep_alive_period_in_seconds=3600,\n",
    ")(\n",
    "    input_data_s3_path=input_s3_url_param,\n",
    "    output_s3_prefix=output_s3_prefix,\n",
    "    tracking_server_arn=tracking_server_arn_param,\n",
    "    experiment_name=experiment_name,\n",
    "    pipeline_run_name=ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    ")\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True)\n",
    "cache_config.expire_after = \"p30d\"\n",
    "\n",
    "# train step\n",
    "step_train = TrainingStep(\n",
    "    name=f\"{project}-autoencoder-train\",\n",
    "    step_args=get_pytorch_autoencoder_estimator(\n",
    "        session=PipelineSession(),\n",
    "        instance_type=train_instance_type_param,\n",
    "        output_s3_url=output_s3_url,\n",
    "        base_job_name=f\"{project}-autoencoder-train\",\n",
    "    ).fit(\n",
    "        {\n",
    "            \"train\": TrainingInput(\n",
    "                step_preprocess['train_data'],\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                step_preprocess['validation_data'],\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "        }\n",
    "    ),\n",
    "    cache_config=cache_config,\n",
    ")    \n",
    "\n",
    "# evaluate step\n",
    "step_evaluate = step(\n",
    "    evaluate_autoencoder,\n",
    "    instance_type=process_instance_type_param,\n",
    "    name=f\"{project}-evaluate\",\n",
    "    keep_alive_period_in_seconds=3600,\n",
    ")(\n",
    "    test_x_data_s3_path=step_preprocess['test_x_data'],\n",
    "    test_y_data_s3_path=step_preprocess['test_y_data'],\n",
    "    model_s3_path=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    output_s3_prefix=output_s3_prefix,\n",
    "    tracking_server_arn=tracking_server_arn_param,\n",
    "    experiment_name=step_preprocess['experiment_name'],\n",
    "    pipeline_run_id=step_preprocess['pipeline_run_id'],\n",
    ")\n",
    "\n",
    "# register model step\n",
    "step_register = step(\n",
    "        register_autoencoder,\n",
    "        name=f\"{project}-register\",\n",
    "        keep_alive_period_in_seconds=3600,\n",
    "    )(\n",
    "        training_job_name=step_train.properties.TrainingJobName,\n",
    "        model_package_group_name=model_package_group_name_param,\n",
    "        model_approval_status=model_approval_status_param,\n",
    "        evaluation_result=step_evaluate['evaluation_result'],\n",
    "        output_s3_prefix=output_s3_url,\n",
    "        tracking_server_arn=tracking_server_arn_param,\n",
    "        experiment_name=step_preprocess['experiment_name'],\n",
    "        pipeline_run_id=step_preprocess['pipeline_run_id'],\n",
    "    )\n",
    "\n",
    "\n",
    "# fail the pipeline execution step\n",
    "step_fail = FailStep(\n",
    "    name=f\"{project}-fail\",\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to ROC AUC Score < \", test_score_threshold_param]),\n",
    ")\n",
    "\n",
    "# condition to check in the condition step (using ROC AUC for autoencoder)\n",
    "condition_gte = ConditionGreaterThanOrEqualTo(\n",
    "        left=step_evaluate['evaluation_result']['anomaly_detection_metrics']['roc_auc']['value'],  \n",
    "        right=test_score_threshold_param,\n",
    ")\n",
    "\n",
    "# conditional register step\n",
    "step_conditional_register = ConditionStep(\n",
    "    name=f\"{project}-check-metrics\",\n",
    "    conditions=[condition_gte],\n",
    "    if_steps=[step_register],\n",
    "    else_steps=[step_fail],\n",
    ")\n",
    "\n",
    "# Create a pipeline object\n",
    "pipeline = Pipeline(\n",
    "    name=f\"{pipeline_name}\",\n",
    "    parameters=[\n",
    "        input_s3_url_param,\n",
    "        process_instance_type_param,\n",
    "        train_instance_type_param,\n",
    "        model_approval_status_param,\n",
    "        test_score_threshold_param,\n",
    "        model_package_group_name_param,\n",
    "        tracking_server_arn_param,\n",
    "        encoding_dim_param,\n",
    "        dropout_rate_param,\n",
    "        learning_rate_param,\n",
    "        batch_size_param,\n",
    "        num_epochs_param,\n",
    "        weight_decay_param,\n",
    "    ],\n",
    "    steps=[step_conditional_register],\n",
    "    pipeline_definition_config=PipelineDefinitionConfig(use_custom_job_prefix=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e10230d-f5a9-458b-a569-c0cbc4986571",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:36:49.931486Z",
     "iopub.status.busy": "2025-08-06T09:36:49.931163Z",
     "iopub.status.idle": "2025-08-06T09:36:56.935434Z",
     "shell.execute_reply": "2025-08-06T09:36:56.934845Z",
     "shell.execute_reply.started": "2025-08-06T09:36:49.931462Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 09:36:50,279 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-west-2-224425919845/from-idea-to-prod-autoencoder-pipeline-06-08-50-22/from-idea-to-prod-register/2025-08-06-09-36-50-279/function\n",
      "2025-08-06 09:36:50,367 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-west-2-224425919845/from-idea-to-prod-autoencoder-pipeline-06-08-50-22/from-idea-to-prod-register/2025-08-06-09-36-50-279/arguments\n",
      "2025-08-06 09:36:50,564 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmposvtpddf/requirements.txt'\n",
      "2025-08-06 09:36:50,589 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-west-2-224425919845/from-idea-to-prod-autoencoder-pipeline-06-08-50-22/from-idea-to-prod-register/2025-08-06-09-36-50-279/pre_exec_script_and_dependencies'\n",
      "2025-08-06 09:36:50,796 sagemaker.remote_function INFO     Copied user workspace to '/tmp/tmp2nxn5tag/temp_workspace/sagemaker_remote_function_workspace'\n",
      "2025-08-06 09:36:51,603 sagemaker.remote_function INFO     Successfully created workdir archive at '/tmp/tmp2nxn5tag/workspace.zip'\n",
      "2025-08-06 09:36:51,882 sagemaker.remote_function INFO     Successfully uploaded workdir to 's3://sagemaker-us-west-2-224425919845/from-idea-to-prod-autoencoder-pipeline-06-08-50-22/sm_rf_user_ws/2025-08-06-09-36-50-279/workspace.zip'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.Dependencies\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.IncludeLocalWorkDir\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.CustomFileFilter.IgnoreNamePatterns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 09:36:53,644 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-west-2-224425919845/from-idea-to-prod-autoencoder-pipeline-06-08-50-22/from-idea-to-prod-evaluate/2025-08-06-09-36-50-279/function\n",
      "2025-08-06 09:36:53,705 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-west-2-224425919845/from-idea-to-prod-autoencoder-pipeline-06-08-50-22/from-idea-to-prod-evaluate/2025-08-06-09-36-50-279/arguments\n",
      "2025-08-06 09:36:53,763 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmp_r3nns0x/requirements.txt'\n",
      "2025-08-06 09:36:53,791 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-west-2-224425919845/from-idea-to-prod-autoencoder-pipeline-06-08-50-22/from-idea-to-prod-evaluate/2025-08-06-09-36-50-279/pre_exec_script_and_dependencies'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.Dependencies\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.IncludeLocalWorkDir\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.CustomFileFilter.IgnoreNamePatterns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 09:36:55,491 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-west-2-224425919845/from-idea-to-prod-autoencoder-pipeline-06-08-50-22/from-idea-to-prod-preprocess/2025-08-06-09-36-50-279/function\n",
      "2025-08-06 09:36:55,542 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-west-2-224425919845/from-idea-to-prod-autoencoder-pipeline-06-08-50-22/from-idea-to-prod-preprocess/2025-08-06-09-36-50-279/arguments\n",
      "2025-08-06 09:36:55,597 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmp308ao68p/requirements.txt'\n",
      "2025-08-06 09:36:55,623 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-west-2-224425919845/from-idea-to-prod-autoencoder-pipeline-06-08-50-22/from-idea-to-prod-preprocess/2025-08-06-09-36-50-279/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-west-2:224425919845:pipeline/from-idea-to-prod-autoencoder-pipeline-06-08-50-22',\n",
       " 'ResponseMetadata': {'RequestId': '41dcb184-1e66-42dc-94c6-6b9ed053aaca',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '41dcb184-1e66-42dc-94c6-6b9ed053aaca',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '118',\n",
       "   'date': 'Wed, 06 Aug 2025 09:36:56 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsert operation serialize the function code, arguments, and other artefacts to S3 where it can be accessed during pipeline's runtime\n",
    "pipeline.upsert(role_arn=sm_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe95847-053e-48b5-82d1-1e54709a975f",
   "metadata": {},
   "source": [
    "# Show the pipeline link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6046d785-9c1c-4fd4-90fd-a61273b2bd87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:37:32.396185Z",
     "iopub.status.busy": "2025-08-06T09:37:32.395883Z",
     "iopub.status.idle": "2025-08-06T09:37:32.700296Z",
     "shell.execute_reply": "2025-08-06T09:37:32.699753Z",
     "shell.execute_reply.started": "2025-08-06T09:37:32.396165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-west-2:224425919845:pipeline/from-idea-to-prod-autoencoder-pipeline-06-08-50-22',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-west-2:224425919845:pipeline/from-idea-to-prod-autoencoder-pipeline-06-08-50-22/execution/bb57oy07ns1e',\n",
       " 'PipelineExecutionDisplayName': 'execution-1754473052584',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'CreationTime': datetime.datetime(2025, 8, 6, 9, 37, 32, 530000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2025, 8, 6, 9, 37, 32, 530000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-west-2:224425919845:user-profile/d-rtctvdud9qsp/studio-user-7788a530',\n",
       "  'UserProfileName': 'studio-user-7788a530',\n",
       "  'DomainId': 'd-rtctvdud9qsp',\n",
       "  'IamIdentity': {'Arn': 'arn:aws:sts::224425919845:assumed-role/tm-ws-SageMakerExecutionRole-Ou4AK8i38tA1/SageMaker',\n",
       "   'PrincipalId': 'AROATIQGTYVSVCQU4RTXO:SageMaker'}},\n",
       " 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-west-2:224425919845:user-profile/d-rtctvdud9qsp/studio-user-7788a530',\n",
       "  'UserProfileName': 'studio-user-7788a530',\n",
       "  'DomainId': 'd-rtctvdud9qsp',\n",
       "  'IamIdentity': {'Arn': 'arn:aws:sts::224425919845:assumed-role/tm-ws-SageMakerExecutionRole-Ou4AK8i38tA1/SageMaker',\n",
       "   'PrincipalId': 'AROATIQGTYVSVCQU4RTXO:SageMaker'}},\n",
       " 'PipelineVersionId': 1,\n",
       " 'ResponseMetadata': {'RequestId': 'b64e3c85-0610-4b0f-8249-825dee9d9903',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b64e3c85-0610-4b0f-8249-825dee9d9903',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1165',\n",
       "   'date': 'Wed, 06 Aug 2025 09:37:32 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_execution = pipeline.start()\n",
    "pipeline_execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3541fc1c-f499-4980-9e9b-8b6bd212f9f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:37:50.949602Z",
     "iopub.status.busy": "2025-08-06T09:37:50.949153Z",
     "iopub.status.idle": "2025-08-06T09:37:51.149462Z",
     "shell.execute_reply": "2025-08-06T09:37:51.148910Z",
     "shell.execute_reply.started": "2025-08-06T09:37:50.949570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'from-idea-to-prod-preprocess',\n",
       "  'StartTime': datetime.datetime(2025, 8, 6, 9, 37, 33, 986000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Executing',\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-west-2:224425919845:training-job/preprocess-autoencoder-bb57oy07ns1e-IzILMJxHMv'}},\n",
       "  'AttemptCount': 1}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_execution.wait() \n",
    "pipeline_execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a4ca9be-b891-4fae-8acb-17b09463266e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T09:38:28.394347Z",
     "iopub.status.busy": "2025-08-06T09:38:28.394005Z",
     "iopub.status.idle": "2025-08-06T09:38:28.545867Z",
     "shell.execute_reply": "2025-08-06T09:38:28.545333Z",
     "shell.execute_reply.started": "2025-08-06T09:38:28.394324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>See <a target=\"top\" href=\"https://studio-d-rtctvdud9qsp.studio.us-west-2.sagemaker.aws/pipelines/from-idea-to-prod-autoencoder-pipeline-06-08-50-22/executions/bb57oy07ns1e/graph\">the pipeline execution</a> in the Studio UI</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PyTorch Autoencoder Pipeline Created and Executed Successfully!\n",
      "üìä Key Changes Made:\n",
      "  - Replaced XGBoost with PyTorch autoencoder\n",
      "  - Updated hyperparameters for autoencoder training\n",
      "  - Modified evaluation metrics for anomaly detection\n",
      "  - Adjusted pipeline steps for unsupervised learning\n",
      "  - Updated bucket prefix to 'autoencoder'\n",
      "  - Changed threshold evaluation to use ROC AUC\n"
     ]
    }
   ],
   "source": [
    "# Show the pipeline execution link\n",
    "display(\n",
    "    HTML('<b>See <a target=\"top\" href=\"https://studio-{}.studio.{}.sagemaker.aws/pipelines/{}/executions/{}/graph\">the pipeline execution</a> in the Studio UI</b>'.format(\n",
    "            domain_id, region, pipeline_name, pipeline_execution.describe()['PipelineExecutionArn'].split('/')[-1]))\n",
    ")\n",
    "\n",
    "print(\"‚úÖ PyTorch Autoencoder Pipeline Created and Executed Successfully!\")\n",
    "print(\"üìä Key Changes Made:\")\n",
    "print(\"  - Replaced XGBoost with PyTorch autoencoder\")\n",
    "print(\"  - Updated hyperparameters for autoencoder training\")\n",
    "print(\"  - Modified evaluation metrics for anomaly detection\")\n",
    "print(\"  - Adjusted pipeline steps for unsupervised learning\")\n",
    "print(\"  - Updated bucket prefix to 'autoencoder'\")\n",
    "print(\"  - Changed threshold evaluation to use ROC AUC\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff6eb9c-b249-4dd6-9bbd-22b21924dd96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
